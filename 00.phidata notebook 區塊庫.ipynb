{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 1.使用 ollama 的 openhermes 模型\n",
    "# 2.使用 phidata 的命令行交互模式 assistant.cli_app()\n",
    "# 3.可以調用 DuckDuckGo 搜尋網路資源\n",
    "# 4.windows 環境偶而會發生ollama 模型載入失敗的問題，此時需開啟 powershell 視窗輸入 wsl --shutdown 關閉 wsl 環境後重開 ubuntu 環境\n",
    "# 案例：\n",
    "# Summarize the top stories on hackernews and reply in traditional chinese.\n",
    "# Today's Top 10 trending Repositories on GitHub? Introduce them using traditional chinese.\n",
    "# 爬取 GitHub Trending 頁面,以繁體中文解說前5的項目\n",
    "# 爬取 GitHub Trending 頁面,以繁體中文解說前5的項目,請使用我已經設定在系統環境變數 GITHUB_API_KEY 來爬取 \n",
    "# Summarize the top 3 stories on hackernews and translate them into traditional chinese.\n",
    "# Summarize the top 3 stories on hackernews and reply in traditional chinese. \n",
    "# Whats happening in Taiwan today? Summarize top 3 stories with sources and translate to traditional chinese.\n",
    "# Whats happening in Taiwan today? Summarize top 3 stories with sources and reply in traditional chinese. \n",
    "# Write a python script to plot a sine wave and save it to disc as a png file sine_wave.png\n",
    "# 搜尋 arxiv 有關GPT-4最新的3篇論文,請以繁體中文markdown格式存檔到 arxiv.md  \n",
    "# 搜尋網路並推薦台中2日遊的景點及行程規劃\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from IPython.display import HTML, display, Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入依賴庫（套件）,assistant 下面有2種\n",
    "from phi.assistant import Assistant\n",
    "from phi.assistant.python import PythonAssistant\n",
    "# llm 有3 大類\n",
    "from phi.llm.openai import OpenAIChat\n",
    "from phi.llm.ollama import Ollama\n",
    "from phi.llm.openai.like import OpenAILike\n",
    "# 不知道是幹嘛的?\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常用的搜尋工具\n",
    "from phi.tools.duckduckgo import DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入 tools(部分)\n",
    "from phi.tools.arxiv import ArxivTools\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from phi.tools.email import EmailTools\n",
    "from phi.tools.file import FileTools\n",
    "# from phi.tools.google import GoogleTools # 官方尚未完成\n",
    "from phi.tools.python import PythonTools\n",
    "from phi.tools.shell import ShellTools\n",
    "from phi.tools.wikipedia import WikipediaTools\n",
    "from phi.tools.website import WebsiteTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = Assistant(\n",
    "    llm=Ollama(model=\"openhermes\"),\n",
    "    tools=[duckdb_tools],\n",
    "    show_tool_calls=True,\n",
    "    add_to_system_prompt=\"\"\"\n",
    "    Here are the tables you have access to:\n",
    "    - movies: Contains information about movies from IMDB.\n",
    "    \"\"\",\n",
    "    debug_mode=True,\n",
    ")\n",
    "assistant.print_response(\"What is the average rating of movies?\", markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-3.5-turbo\n",
    "assistant = Assistant(\n",
    "    llm=OpenAIChat(model=\"gpt-3.5-turbo\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LM Studio：base_url=\"http://localhost:1234/v1\"\n",
    "# freegpt35：base_url=\"http://localhost:3040/v1\"\n",
    "assistant = Assistant(\n",
    "    llm=OpenAILike(base_url=\"http://localhost:3040/v1\"),\n",
    "    tools=[DuckDuckGo()],\n",
    "    show_tool_calls=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama\n",
    "# 注意！注意！注意！assistant 加上讓他講中文的 system_promt，會導致無法調用函數的惡果！ \n",
    "assistant = Assistant(\n",
    "    llm=Ollama(model=\"openhermes\"),\n",
    "    # system_prompt=\"請一律使用繁體中文回復\", # 不可以亂加這個\n",
    "    tools=[DuckDuckGo()],\n",
    "    debug_mode=True,\n",
    "    show_tool_calls=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要讓它吐中文，要放在這裡\n",
    "assistant.print_response(\"Whats happening in Taiwan today? Please reply in traditional chinese\", markdown=True)\n",
    "# assistant.print_response(\"使用DuckDuckGo搜尋網路並推薦台中2日遊的景點及行程規劃\", markdown=True)\n",
    "# assistant.print_response(\"Share a 2 sentence quick healthy breakfast recipe. You should only use traditional chinese to express\", markdown=True)\n",
    "# assistant.cli_app(markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\assistant_stream_off.py\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "\n",
    "assistant = Assistant(\n",
    "    # llm=Ollama(), # 可以不指定 Ollama 的大模型名稱\n",
    "    llm=Ollama(model=\"mistral\"),\n",
    "    description=\"You help people with their health and fitness goals.\",\n",
    "    debug_mode=True,\n",
    ")\n",
    "assistant.print_response(\"Share a quick healthy breakfast recipe. Reply in traditional chinese.\", stream=True, markdown=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\assistant.py\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "# 載入工具\n",
    "from phi.tools.arxiv import ArxivTools\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from phi.tools.email import EmailTools\n",
    "from phi.tools.file import FileTools\n",
    "from phi.tools.google import GoogleTools\n",
    "from phi.tools.python import PythonTools\n",
    "from phi.tools.shell import ShellTools\n",
    "from phi.tools.website import WebsiteTools\n",
    "from phi.tools.wikipedia import WikipediaTools\n",
    "\n",
    "assistant = Assistant(\n",
    "    llm=Ollama(model=\"openhermes\"),\n",
    "    description=\"You help people with their health and fitness goals.\",\n",
    "    debug_mode=True,\n",
    ")\n",
    "assistant2 = Assistant(\n",
    "    llm=Ollama(model=\"openhermes\"),\n",
    "    # system_prompt=\"請一律使用繁體中文回復\",\n",
    "    debug_mode=True,\n",
    "    tools=[DuckDuckGo()],\n",
    "    show_tool_calls=True,\n",
    ")\n",
    "# assistant1.print_response(\"Share 2 quick healthy breakfast recipes.\", markdown=True)\n",
    "assistant2.print_response(\"Whats happening in Taiwan today? Summarize top 3 stories with sources and reply in traditional chinese.\", markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\auto_assistant.py\n",
    "# auto assistant 酷喔~~~\n",
    "# 不過，執行有錯誤，待研究\n",
    "from phi.assistant import Assistant\n",
    "from phi.knowledge.pdf import PDFUrlKnowledgeBase\n",
    "from phi.vectordb.pgvector import PgVector2\n",
    "from phi.llm.ollama import Ollama\n",
    "from resources import vector_db\n",
    "\n",
    "knowledge_base = PDFUrlKnowledgeBase(\n",
    "    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n",
    "    vector_db=PgVector2(\n",
    "        collection=\"recipes\",\n",
    "        db_url=vector_db.get_db_connection_local(),\n",
    "    ),\n",
    ")\n",
    "knowledge_base.load(recreate=False)\n",
    "\n",
    "auto_assistant = Assistant(\n",
    "    knowledge_base=knowledge_base,\n",
    "    llm=Ollama(model=\"openhermes_assistant\"),\n",
    "    # use_tools adds the `search_knowledge_base` and `get_chat_history` functions\n",
    "    use_tools=True,\n",
    "    show_tool_calls=True,\n",
    ")\n",
    "\n",
    "# will call `search_knowledge_base` to generate this response\n",
    "auto_assistant.print_response('How do I make pad thai?')\n",
    "# will call `get_chat_history` to generate this response\n",
    "auto_assistant.print_response('What was my last question?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\cli.py\n",
    "# 1.使用 ollama 的 openhermes 模型\n",
    "# 2.使用 phidata 的命令行交互模式 assistant.cli_app()\n",
    "# 3.可以調用 DuckDuckGo 搜尋網路資源\n",
    "# 4.windows 環境偶而會發生 ollama 模型載入失敗的問題，此時需開啟 powershell 視窗輸入 wsl --shutdown 關閉 wsl 環境後重開 ubuntu 環境\n",
    "# 載入套件\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "\n",
    "assistant = Assistant(\n",
    "    llm=Ollama(model=\"openhermes_assistant\"),\n",
    "    system_prompt=\"You ara a helpful assistant.\",\n",
    "\tdescription=\"You can use provided tools to help users solve any problems. and you should always reply to user in traditional chinese\",\n",
    "    tools=[DuckDuckGo()],\n",
    "    show_tool_calls=True,\n",
    "    debug_mode=True\n",
    "    )\n",
    "assistant.cli_app(markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\data_assistant.py\n",
    "import json\n",
    "from phi.assistant.duckdb import DuckDbAssistant\n",
    "from phi.llm.ollama import Ollama\n",
    "\n",
    "duckdb_assistant = DuckDbAssistant(\n",
    "\n",
    "    semantic_model=json.dumps({\n",
    "    \n",
    "        \"tables\": [\n",
    "            {\n",
    "                \"name\": \"movies\",\n",
    "                \"description\": \"Contains information about movies from IMDB.\",\n",
    "                \"path\": \"https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\",\n",
    "            }\n",
    "        ]\n",
    "    }),\n",
    "    llm=Ollama(model=\"openhermes_assistant\"),\n",
    ")\n",
    "\n",
    "duckdb_assistant.print_response(\"What is the average rating of movies? Show me the SQL.\", markdown=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\embeddings.py\n",
    "from phi.embedder.ollama import OllamaEmbedder\n",
    "\n",
    "embedder = OllamaEmbedder(model=\"nomic-embed-text\", dimensions=768)\n",
    "embeddings = embedder.get_embedding(\"Embed me\")\n",
    "\n",
    "print(f\"Embeddings: {embeddings}\")\n",
    "print(f\"Dimensions: {len(embeddings)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\hermes.py\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from phi.tools.arxiv import ArxivTools\n",
    "\n",
    "hermes = Assistant(\n",
    "    # llm=Ollama(model=\"openhermes_assistant\"), # 很好的模型，可以調用函數\n",
    "    llm=Ollama(model=\"openhermes\"),\n",
    "    # llm=Ollama(model=\"openchat\"), # 很遜的模型，不會調用函數\n",
    "    tools=[DuckDuckGo()],\n",
    "    show_tool_calls=True,\n",
    ")\n",
    "# Search Today's Top 5 trending Repositories on GitHub? Introduce them using traditional chinese\n",
    "# hermes.print_response(\"Whats happening in Taiwan? Summarize top stories with sources. 並使用繁體中文回覆\", markdown=True)\n",
    "hermes.print_response(\"Whats happening in Taiwan? Summarize top 5 social news with sources and at least one new pictures link. 並使用繁體中文回覆\", markdown=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\hn_assistant.py\n",
    "import json\n",
    "import httpx\n",
    "\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "def get_top_hackernews_stories(num_stories: int = 10) -> str:\n",
    "    \"\"\"Use this function to get top stories from Hacker News.\n",
    "\n",
    "    Args:\n",
    "        num_stories (int): Number of stories to return. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        str: JSON string of top stories.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch top story IDs\n",
    "    response = httpx.get('https://hacker-news.firebaseio.com/v0/topstories.json')\n",
    "    story_ids = response.json()\n",
    "\n",
    "    # Fetch story details\n",
    "    stories = []\n",
    "    for story_id in story_ids[:num_stories]:\n",
    "        story_response = httpx.get(f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json')\n",
    "        story = story_response.json()\n",
    "        if \"text\" in story:\n",
    "            story.pop(\"text\", None)\n",
    "        stories.append(story)\n",
    "    return json.dumps(stories)\n",
    "\n",
    "assistant = Assistant(\n",
    "    llm=Ollama(model=\"openhermes_assistant\"),\n",
    "    tools=[get_top_hackernews_stories],\n",
    "    debug_mode=True,\n",
    "    show_tool_calls=True\n",
    ")\n",
    "# assistant = Assistant(tools=[get_top_hackernews_stories], show_tool_calls=True)\n",
    "assistant.print_response(\"Summarize the top 5 stories and 連結 on hackernews and reply in traditional chinese.\", markdown=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\image.py\n",
    "from pathlib import Path\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "\n",
    "assistant = Assistant(llm=Ollama(model=\"llava\"))\n",
    "\n",
    "image_path = Path(__file__).parent / \"test_image.jpeg\"\n",
    "assistant.print_response(\n",
    "    \"Whats in the image? 請使用繁體中文回復\",\n",
    "    images=[image_path.read_bytes()],\n",
    "    markdown=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\openai_api.py\n",
    "# Please install dependencies using: pip install -U ollama phidata openai\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama.openai import OllamaOpenAI\n",
    "\n",
    "assistant = Assistant(\n",
    "    llm=OllamaOpenAI(model=\"qwen\"),\n",
    "    system_prompt=\"Who are you and who created you? Respond in 1 sentence. 請一律使用繁體中文回復\",\n",
    ")\n",
    "assistant.print_response(markdown=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\pydantic_output.py\n",
    "# 這個範例有趣，定義一個 MovieScript 的輸出類別，讓 movie_assistant 能夠輸出 MovieScript 類別的實例。\n",
    "# 讓 gpt 解釋這段程式碼\n",
    "\"\"\"\n",
    "這段程式碼是一個用於生成電影劇本概念的程式。讓我們逐段來解釋：\n",
    "\n",
    "導入必要的模塊：\n",
    "typing.List：用於定義列表類型的類型提示。\n",
    "pydantic.BaseModel 和 pydantic.Field：用於定義數據模型和模型字段的 Pydantic 库。\n",
    "rich.pretty.pprint：用於美化打印輸出的 Rich 库中的 pprint 函数。\n",
    "phi.assistant.Assistant 和 phi.llm.ollama.Ollama：用於生成電影劇本的助手類和 Ollama 大腦模型。\n",
    "\n",
    "定義 MovieScript 模型：\n",
    "MovieScript 繼承自 BaseModel，它是一個數據模型，用於描述電影劇本的結構。\n",
    "有幾個字段，包括 setting（場景）、ending（結局）、genre（類型）、name（名稱）、characters（角色）和 storyline（故事概要）。\n",
    "每個字段都有一個描述，以便使用者理解。\n",
    "\n",
    "創建 Assistant 對象：\n",
    "movie_assistant 是一個助手對象，用於生成電影劇本概念。\n",
    "通過傳入 Ollama 模型，它使用了一個名為 \"openhermes\" 的模型來生成劇本概念。\n",
    "description 參數提供了對助手功能的簡要描述，並要求使用中文詼諧的語氣。\n",
    "output_model 指定了劇本概念的輸出模型，這裡使用了之前定義的 MovieScript。\n",
    "debug_mode 設置為 True，以啟用調試模式。\n",
    "\n",
    "運行 Assistant：\n",
    "通過調用 movie_assistant.run(\"First love\")，助手開始運行，並提供 \"First love\" 作為輸入。\n",
    "pprint 函數用於美化打印輸出。\n",
    "總之，這段程式碼定義了一個助手，用於生成具有指定場景、結局、類型等元素的電影劇本概念，並且通過 Pydantic 库來驗證輸入和輸出的數據模型。\n",
    "\n",
    "要求更詳細的解說\n",
    "導入必要的模塊：\n",
    "typing.List：這個模塊允許我們使用 List 類型提示，它用於指定一個列表中元素的類型。\n",
    "pydantic.BaseModel 和 pydantic.Field：Pydantic 是一個用於數據驗證和序列化的庫。在這裡，我們使用它來定義 MovieScript 類型，並添加一些驗證規則，如必填字段和字段描述。\n",
    "rich.pretty.pprint：Rich 是一個用於在終端中創建美觀且可自定義的文本輸出的庫。pprint 函數用於美化打印輸出的數據。\n",
    "phi.assistant.Assistant 和 phi.llm.ollama.Ollama：這些是用於生成電影劇本的助手和 Ollama 大腦模型的相關模塊。Assistant 類負責處理用戶輸入並生成相應的劇本概念，而 Ollama 則是一個語言模型，用於生成文本。\n",
    "\n",
    "定義 MovieScript 模型：\n",
    "MovieScript 是一個 Pydantic 的數據模型，用於表示電影劇本的結構。\n",
    "它包含了幾個字段：\n",
    "setting：表示電影的場景。\n",
    "ending：表示電影的結局。\n",
    "genre：表示電影的類型。\n",
    "name：表示電影的名稱。\n",
    "characters：表示電影中的角色列表。\n",
    "storyline：表示電影的故事概要。\n",
    "每個字段都使用 Field 函數進行了配置，其中 ... 表示該字段是必填的，並且提供了對該字段的描述。\n",
    "\n",
    "創建 Assistant 對象：\n",
    "Assistant 類是用於生成劇本概念的助手。在這裡，我們創建了一個名為 movie_assistant 的助手對象。\n",
    "我們傳入了一個 Ollama 的實例，並指定了使用的模型為 \"openhermes\"。這個模型將用於生成電影劇本的概念。\n",
    "我們還提供了一個簡要的描述，以及設置了 debug_mode 為 True，以啟用調試模式。\n",
    "\n",
    "運行 Assistant：\n",
    "一切準備就緒後，我們調用 movie_assistant.run(\"First love\") 方法運行助手。\n",
    "這將生成一個電影劇本概念，並將其打印出來，使用 pprint 函數美化輸出。\n",
    "這就是這段程式碼的詳細解釋。它的主要功能是生成具有指定場景、結局、類型等元素的電影劇本概念，並通過 Pydantic 库來驗證輸入和輸出的數據模型。\n",
    "\n",
    "問：typing.List：這個模塊允許我們使用 List 類型提示，它用於指定一個列表中元素的類型。\n",
    "答：\n",
    "沒錯，typing 模組中的 List 類型提示允許我們指定列表中元素的類型。這在 Python 中是一種靜態類型提示的方式，它有助於提高程式碼的可讀性和可維護性。\n",
    "例如，假設我們有一個列表，其中包含多個整數：\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "使用 typing 模組中的 List 類型提示，我們可以指定這個列表的元素類型是整數，如下所示：\n",
    "from typing import List\n",
    "my_list: List[int] = [1, 2, 3, 4, 5]\n",
    "這樣一來，當其他人讀取或維護這段程式碼時，就能清楚地知道 my_list 是一個整數列表，而不需要進一步查看程式碼內容。這種類型提示還可以讓 IDE 在開發過程中提供更好的代碼自動完成和錯誤檢測功能，從而提高開發效率和程式碼的健壯性。\n",
    "\n",
    "問：\n",
    "答：\n",
    "這段程式碼定義了一個名為 MovieScript 的類，它是一個 Pydantic 的數據模型，用於描述電影劇本的結構。讓我們來逐行解釋每個字段：\n",
    "\n",
    "setting：\n",
    "這是電影劇本中的場景，它的類型是字串 (str)。\n",
    "這個字段使用了 Field 函數進行配置，其中 ... 表示該字段是必填的。\n",
    "提供了對這個字段的描述，指明了使用者應該提供一個適合的場景來描述一部大片。\n",
    "\n",
    "ending：\n",
    "這是電影劇本中的結局，它的類型也是字串 (str)。\n",
    "同樣地，這個字段也是必填的，如果結局沒有被提供，則提供一個快樂的結局。\n",
    "提供了對這個字段的描述，指明了使用者應該提供電影的結局。\n",
    "\n",
    "genre：\n",
    "這是電影劇本中的類型，它的類型是字串 (str)。\n",
    "同樣地，這個字段也是必填的，如果類型沒有被提供，則從動作、驚悚或浪漫喜劇中選擇一個。\n",
    "提供了對這個字段的描述，指明了使用者應該提供電影的類型。\n",
    "\n",
    "name：\n",
    "這是電影的名稱，它的類型也是字串 (str)。\n",
    "同樣地，這個字段也是必填的。\n",
    "提供了對這個字段的描述，指明了使用者應該提供一個以繁體中文表達的名稱。\n",
    "\n",
    "characters：\n",
    "這是電影中角色的名稱列表，它的類型是字串列表 (List[str])。\n",
    "同樣地，這個字段也是必填的。\n",
    "提供了對這個字段的描述，指明了使用者應該提供以繁體中文表達的角色名稱。\n",
    "\n",
    "storyline：\n",
    "這是電影的故事概要，它的類型是字串 (str)。\n",
    "同樣地，這個字段也是必填的。\n",
    "提供了對這個字段的描述，指明了使用者應該提供一個以繁體中文表達的令人興奮的三句話故事概要。\n",
    "總的來說，這個 MovieScript 類型定義了一個完整的電影劇本結構，並且使用 Pydantic 的驗證功能確保了每個字段都被正確填寫。\n",
    "\"\"\"\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from rich.pretty import pprint\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "\n",
    "class MovieScript(BaseModel):\n",
    "    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n",
    "    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n",
    "    genre: str = Field(\n",
    "        ..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\"\n",
    "    )\n",
    "    name: str = Field(..., description=\"Give a name to this movie. express with traditional chinese.\")\n",
    "    characters: List[str] = Field(..., description=\"Name of characters for this movie. express with traditional chinese.\")\n",
    "    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting! express with traditional chinese.\")\n",
    "\n",
    "movie_assistant = Assistant(\n",
    "    llm=Ollama(model=\"openhermes\"),\n",
    "    description=\"You help people write movie ideas. 請使用中文詼諧的語氣表達\",\n",
    "    output_model=MovieScript,\n",
    "    # output_model=MovieScript(ending=\"all died\"), # 不能這樣子設，上面定義的類別是給 LLM 輸出用的\n",
    "    # debug_mode=True,\n",
    ")\n",
    "\n",
    "# 給定字串而已，應該是當成提示詞，\n",
    "# movie_assistant.run ??? 這樣也可以???\n",
    "pprint(movie_assistant.run(\"First love\"))\n",
    "\n",
    "# 輸出的部分，endding 沒給，就會是快樂結局，輸出5個元素\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\PythonAssistant.py\n",
    "from phi.assistant.python import PythonAssistant\n",
    "from phi.file.local.csv import CsvFile\n",
    "# 載入套件\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "from phi.llm.openai.like import OpenAILike\n",
    "\n",
    "# 加入9個工具之後，一直抱錯，只好試著加入有的沒的\n",
    "from pydantic import BaseModel, PydanticUserError, field_validator\n",
    "\n",
    "# 載入工具\n",
    "from phi.tools.arxiv import ArxivTools\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from phi.tools.email import EmailTools\n",
    "from phi.tools.file import FileTools\n",
    "from phi.tools.google import GoogleTools\n",
    "from phi.tools.python import PythonTools\n",
    "from phi.tools.shell import ShellTools\n",
    "from phi.tools.website import WebsiteTools\n",
    "from phi.tools.wikipedia import WikipediaTools\n",
    "\n",
    "# 建立函數當成工具使用\n",
    "def get_top_hackernews_stories(num_stories: int = 10) -> str:\n",
    "    \"\"\"Use this function to get top stories from Hacker News.\n",
    "    Args:\n",
    "        num_stories (int): Number of stories to return. Defaults to 10.\n",
    "    Returns:\n",
    "        str: JSON string of top stories.\n",
    "    \"\"\"\n",
    "    # Fetch top story IDs\n",
    "    response = httpx.get('https://hacker-news.firebaseio.com/v0/topstories.json')\n",
    "    story_ids = response.json()\n",
    "\n",
    "python_assistant = PythonAssistant(\n",
    "    # llm 都不指定，原本預設使用 gpt4，已修改為使用 gpt3.5-turbo\n",
    "\t# llm=Ollama(model=\"codellama\"),            # 可以跑出結果，但結果錯誤 4.917 \n",
    "\t# llm=Ollama(model=\"llama2\"),               # 6.7、6.4 多次不同結果\n",
    "\t# llm=Ollama(model=\"llama2-uncensored\"),    # 可以跑出結果，但結果錯誤 7.15 \n",
    "\t# llm=Ollama(model=\"llava\"),                # 可以跑出結果，但結果錯誤 6.5\n",
    "\t# llm=Ollama(model=\"mistral\"),              # 任務失敗，輸出空白結果\n",
    "\t# llm=Ollama(model=\"neural-chat\"),          # 可以跑出結果，但結果錯誤 6.9 \n",
    "\t# llm=Ollama(model=\"openchat\"),             # The average rating of movies is not provided in the given data file.\n",
    "\tllm=Ollama(model=\"openhermes\"),           # 可以跑出結果，但結果錯誤 7.1\n",
    "    # llm=Ollama(model=\"openhermes_assistant\"),\n",
    "\t# llm=Ollama(model=\"qwen\"),                 # 任務失敗，很久還跑出亂碼\n",
    "\t# llm=Ollama(model=\"starling-lm\"),          # 可以跑出結果，但結果錯誤 7.3\n",
    "\t# 這些 ollama 的大模型都沒有成功調用 python 的 tools 來寫程式碼計算平均分數。失敗~\n",
    "\t# 如果使用 gpt-3.5-turbo 幾乎每次都成功\n",
    "    # 調用 LM Studio\n",
    "\t# llm=OpenAILike(base_url=\"http://localhost:1234/v1\"),\n",
    "    files=[\n",
    "        CsvFile(\n",
    "            path=\"https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\",\n",
    "            description=\"Contains information about movies from IMDB.\",\n",
    "        )\n",
    "    ],\n",
    "    pip_install=True,\n",
    "    show_tool_calls=True,\n",
    "\n",
    ")\n",
    "\n",
    "python_assistant.print_response(\"What is the average rating of movies?\", markdown=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\PythonAssistant.py\n",
    "from phi.assistant.python import PythonAssistant\n",
    "from phi.file.local.csv import CsvFile\n",
    "from phi.llm.ollama import Ollama\n",
    "\n",
    "# 載入工具\n",
    "from phi.tools.arxiv import ArxivTools\n",
    "from phi.tools.email import EmailTools\n",
    "from phi.tools.file import FileTools\n",
    "from phi.tools.python import PythonTools\n",
    "from phi.tools.shell import ShellTools\n",
    "from phi.tools.website import WebsiteTools\n",
    "from phi.tools.wikipedia import WikipediaTools\n",
    "\n",
    "# 建立函數當成工具使用\n",
    "def get_top_hackernews_stories(num_stories: int = 10) -> str:\n",
    "    \"\"\"Use this function to get top stories from Hacker News.\n",
    "    Args:\n",
    "        num_stories (int): Number of stories to return. Defaults to 10.\n",
    "    Returns:\n",
    "        str: JSON string of top stories.\n",
    "    \"\"\"\n",
    "    # Fetch top story IDs\n",
    "    response = httpx.get('https://hacker-news.firebaseio.com/v0/topstories.json')\n",
    "    story_ids = response.json()\n",
    "\n",
    "python_assistant = PythonAssistant(\n",
    "\tllm=Ollama(model=\"wizardlm2\"), \n",
    "    files=[\n",
    "        CsvFile(\n",
    "            path=\"https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\",\n",
    "            description=\"Contains information about movies from IMDB.\",\n",
    "        )\n",
    "    ],\n",
    "    pip_install=True,\n",
    "    show_tool_calls=True,\n",
    "\n",
    ")\n",
    "\n",
    "python_assistant.print_response(\"What is the average rating of movies?\", markdown=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\qwen.py\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "\n",
    "qwen = Assistant(llm=Ollama(model=\"qwen\"))\n",
    "\n",
    "qwen.print_response(\"Give me a short introduction to large language model. 請一律使用繁體中文回復\", markdown=True)\n",
    "qwen.print_response(\"Write a python function to calculate the factorial of a number. 請一律使用繁體中文回復\", markdown=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\resources.py\n",
    "\"\"\"\n",
    "Lets create a PDF Assistant that can answer questions from a PDF. We'll use PgVector for knowledge and storage.\n",
    "Knowledge Base: information that the Assistant can search to improve its responses (uses a vector db).\n",
    "Storage: provides long term memory for Assistants (uses a database).\n",
    "Run PgVector\n",
    "Install docker desktop for running PgVector in a container.\n",
    "Create a file resources.py with the following contents\n",
    "\"\"\"\n",
    "from phi.docker.app.postgres import PgVectorDb\n",
    "from phi.docker.resources import DockerResources\n",
    "\n",
    "# -*- PgVector running on port 5432:5432\n",
    "vector_db = PgVectorDb(\n",
    "    pg_user=\"ai\",\n",
    "    pg_password=\"ai\",\n",
    "    pg_database=\"ai\",\n",
    "    debug_mode=True,\n",
    ")\n",
    "\n",
    "# -*- DockerResources\n",
    "dev_docker_resources = DockerResources(apps=[vector_db])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\tool_call.py\n",
    "import typer\n",
    "from phi.assistant import Assistant\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from phi.llm.ollama import Ollama\n",
    "\n",
    "assistant = Assistant(\n",
    "    llm=Ollama(model=\"openhermes\"),\n",
    "    # llm=Ollama(model=\"qwen\"),\n",
    "    tools=[DuckDuckGo()],\n",
    "    show_tool_calls=True,\n",
    "    # instructions=[\"Make sure your answers are well formatted.\"],\n",
    "    instructions=[\"Make sure your answers are well formatted. 請一律使用繁體中文回復\"],\n",
    "    debug_mode=True,\n",
    ")\n",
    "assistant.print_response(\"Whats happening in AI 前緣科技. 請一律使用繁體中文回復\", markdown=False)\n",
    "\n",
    "assistant.print_response(\"Tell me about OpenAI Sora\", markdown=True)\n",
    "\n",
    "def tool_call(model: str = \"openhermes\", debug: bool = False):\n",
    "    print(f\"============= Running: {model} =============\")\n",
    "    Assistant(\n",
    "        llm=Ollama(model=model),\n",
    "        tools=[DuckDuckGo()],\n",
    "        show_tool_calls=True,\n",
    "        debug_mode=debug,\n",
    "    ).cli_app(markdown=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    typer.run(tool_call)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\ollama\\who_are_you.py\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "\n",
    "prompt = \"Who are you and who created you? Answer in 1 short sentence. 請一律使用繁體中文回復\"\n",
    "temp = 0.3\n",
    "# models = [\"phi\", \"llava\", \"llama2\", \"mixtral\", \"openhermes\", \"tinyllama\"]\n",
    "models = [\"codellama\", \"llama2\", \"llama2-uncensored\", \"llava\", \"mistral\", \"neural-chat\", \"openchat\", \"openhermes\", \"qwen\", \"starling-lm\"]\n",
    "for model in models:\n",
    "    print(f\"================ {model} ================\")\n",
    "    Assistant(llm=Ollama(model=model, options={\"temperature\": temp}), system_prompt=prompt).print_response(\n",
    "        markdown=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\openhermes\\assistant.py\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "\n",
    "assistant = Assistant(\n",
    "    llm=Ollama(model=\"openhermes\"),\n",
    "    description=\"You help people with their health and fitness goals.\",\n",
    ")\n",
    "assistant.print_response(\"Share a quick healthy breakfast recipe.\", markdown=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\openhermes\\tool_call.py\n",
    "from phi.assistant import Assistant\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from phi.llm.ollama import Ollama\n",
    "\n",
    "assistant = Assistant(\n",
    "    llm=Ollama(model=\"openhermes\"),\n",
    "    tools=[DuckDuckGo()],\n",
    "    show_tool_calls=True,\n",
    "    debug_mode=True\n",
    ")\n",
    "assistant.print_response(\"Tell me about OpenAI Sora\", markdown=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\openhermes\\embeddings.py\n",
    "from phi.embedder.ollama import OllamaEmbedder\n",
    "\n",
    "embedder = OllamaEmbedder(model=\"openhermes\", dimensions=4096)\n",
    "embeddings = embedder.get_embedding(\"Embed me\")\n",
    "\n",
    "print(f\"Embeddings: {embeddings[:10]}\")\n",
    "print(f\"Dimensions: {len(embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\openhermes\\data_analyst.py\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "from phi.tools.duckdb import DuckDbTools\n",
    "\n",
    "\n",
    "duckdb_tools = DuckDbTools(create_tables=False, export_tables=False, summarize_tables=False)\n",
    "duckdb_tools.create_table_from_path(\n",
    "    path=\"https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\", table=\"movies\"\n",
    ")\n",
    "\n",
    "assistant = Assistant(\n",
    "    llm=Ollama(model=\"openhermes\"),\n",
    "    tools=[duckdb_tools],\n",
    "    show_tool_calls=True,\n",
    "    add_to_system_prompt=\"\"\"\n",
    "    Here are the tables you have access to:\n",
    "    - movies: Contains information about movies from IMDB.\n",
    "    \"\"\",\n",
    "    debug_mode=True,\n",
    ")\n",
    "assistant.print_response(\"What is the average rating of movies?\", markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例 cookbook\\openhermes\\pydantic_output.py\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from rich.pretty import pprint\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.ollama import Ollama\n",
    "\n",
    "class MovieScript(BaseModel):\n",
    "    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n",
    "    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n",
    "    genre: str = Field(\n",
    "        ..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\"\n",
    "    )\n",
    "    name: str = Field(..., description=\"Give a name to this movie\")\n",
    "    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n",
    "    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n",
    "\n",
    "\n",
    "movie_assistant = Assistant(\n",
    "    llm=Ollama(model=\"openhermes\"),\n",
    "    description=\"You help people write movie ideas.\",\n",
    "    output_model=MovieScript,\n",
    "    # debug_mode=True,\n",
    ")\n",
    "\n",
    "pprint(movie_assistant.run(\"TAIWAN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自訂函數當成工具\n",
    "import httpx, json\n",
    "def get_top_hackernews_stories(num_stories: int = 10) -> str:\n",
    "    \"\"\"Use this function to get top stories from Hacker News.\n",
    "\n",
    "    Args:\n",
    "        num_stories (int): Number of stories to return. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        str: JSON string of top stories.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch top story IDs\n",
    "    response = httpx.get('https://hacker-news.firebaseio.com/v0/topstories.json')\n",
    "    story_ids = response.json()\n",
    "\n",
    "    # Fetch story details\n",
    "    stories = []\n",
    "    for story_id in story_ids[:num_stories]:\n",
    "        story_response = httpx.get(f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json')\n",
    "        story = story_response.json()\n",
    "        if \"text\" in story:\n",
    "            story.pop(\"text\", None)\n",
    "        stories.append(story)\n",
    "    return json.dumps(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assistant = PythonAssistant(\n",
    "    # 沒有支援 gemini\n",
    "\t# llm=Ollama(model=\"codellama\"),            # 可以跑出結果，但結果錯誤 4.917 \n",
    "\t# llm=Ollama(model=\"llama2\"),               # 6.7、6.4 多次不同結果\n",
    "\t# llm=Ollama(model=\"llama2-uncensored\"),    # 可以跑出結果，但結果錯誤 7.15 \n",
    "\t# llm=Ollama(model=\"llava\"),                  # 可以跑出結果，但結果錯誤 6.5\n",
    "\t# llm=Ollama(model=\"mistral\"),               # 任務失敗，沒跑出結果\n",
    "\t# llm=Ollama(model=\"neural-chat\"),            # 可以跑出結果，但結果錯誤 6.9 \n",
    "\t# llm=Ollama(model=\"openchat\"),               # The average rating of movies is not provided in the given data file.\n",
    "\t# llm=Ollama(model=\"openhermes\"),           # 可以跑出結果，但結果錯誤 7.1\n",
    "    # llm=Ollama(model=\"openhermes\"),\n",
    "\t# llm=Ollama(model=\"qwen\"),                 # 任務失敗，很久還跑出亂碼\n",
    "\t# llm=Ollama(model=\"starling-lm\"),            # 可以跑出結果，但結果錯誤 7.3\n",
    "\t# 這些 ollama 的大模型都沒有成功調用 python 的 tools 來寫程式碼計算平均分數。失敗~\n",
    "    \n",
    "\t# 如果使用 gpt-3.5-turbo 幾乎每次都成功, 函數調用也沒問題\n",
    "    llm=OpenAIChat(model=\"gpt-3.5-turbo\"),\n",
    "\t\n",
    "\t# llm=OpenAILike(base_url=\"http://localhost:1234/v1\"),\n",
    "\t\n",
    "\tsystem_prompt=\"You ara a helpful assistant.\",\n",
    "\tdescription=\"You can use provided tools to help users solve any problems.\",\n",
    "\tuse_tools=True,\n",
    "\tshow_tool_calls=True,\n",
    "\ttools=[get_top_hackernews_stories, ArxivTools(), DuckDuckGo(), EmailTools(), FileTools(), PythonTools(), ShellTools(), WebsiteTools(), WikipediaTools()],  # GoogleTools(), \n",
    "\tpip_install=True,\n",
    "\tsave_and_run=True,\n",
    "\trun_code=True,\n",
    "\tdebug_mode=True,\n",
    "\tmarkdown=True\n",
    "\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the top stories on hackernews today and translate to traditional chinese.\n",
    "# Search the top 5 stories on hackernews today. Summarize them and give me the links.\n",
    "# 搜尋 wikipedia,列出五月天歷年的專輯清單(無需其他說明),寫入檔案 五月天.txt\n",
    "task=\"Summarize the top 5 stories on hackernews today. Reply in traditional chinese\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant.print_response(task, markdown=True)\n",
    "# assistant.cli_app(markdown=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
